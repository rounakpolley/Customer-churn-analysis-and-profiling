{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn import tree\n",
    "from sklearn.datasets import load_wine\n",
    "from IPython.display import SVG\n",
    "from IPython.display import display\n",
    "from sklearn import metrics\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Install graphviz\n",
    "#conda install python-graphviz\n",
    "from graphviz import Source  \n",
    "\n",
    "#Install ipywidgets\n",
    "#conda install -c conda-forge ipywidgets\n",
    "from ipywidgets import interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2644 689 || 5605 1416\n"
     ]
    }
   ],
   "source": [
    "df1_train = pd.read_pickle(\"./df1_train.pkl\")\n",
    "df1_test  = pd.read_pickle(\"./df1_test.pkl\")\n",
    "\n",
    "df2_train = pd.read_pickle(\"./df2_train.pkl\")\n",
    "df2_test  = pd.read_pickle(\"./df2_test.pkl\")\n",
    "print(str(len(df1_train))+\" \"+str(len(df1_test))+\" || \"+str(len(df2_train))+\" \"+str(len(df2_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc77f962d93d4aa4bff26bb1ad109073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='dataset', options=(1, 2), value=1), Dropdown(description='criteria…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "criterion         : The function to measure the quality of a split.\n",
    "                    “gini” for the Gini impurity and “entropy” for the information gain.\n",
    "splitter          : The strategy used to choose the split at each node\n",
    "min_samples_split : The minimum number of samples required to split an internal node\n",
    "                    If int, then consider min_samples_split as the minimum number\n",
    "                    If float, then min_samples_split is a fraction and ceil(min_samples_split * n_samples) are the minimum number\n",
    "                    of samples for each split.\n",
    "    ***[i.e fraction of the training dataset size]\n",
    "    ***    0.01 of 2644 = 26 i.e < 26 entires and a node cannot be split!!! (56 for df2)\n",
    "min_samples_leaf : The minimum number of samples required to be at a leaf node. A split point at any depth will only be considered\n",
    "                    if it leaves at least min_samples_leaf training samples in each of the left and right branches.\n",
    "                    This may have the effect of smoothing the model, especially in regression.\n",
    "                    ***Same int/float as above\n",
    "'''\n",
    "\n",
    "def run_decission_tree(dataset, criteria, split_type, max_depth, min_split, min_leaf):\n",
    "    if(dataset == 1):\n",
    "        X_train       = df1_train.iloc[:,:-1]\n",
    "        y_train       = df1_train.iloc[:,-1:]\n",
    "        X_test        = df1_test.iloc[:,:-1]\n",
    "        y_test        = df1_test.iloc[:,-1:]\n",
    "        feature_names = df1_train.columns[:-1]\n",
    "    elif(dataset == 2):\n",
    "        X_train       = df2_train.iloc[:,:-1]\n",
    "        y_train       = df2_train.iloc[:,-1:]\n",
    "        X_test        = df2_test.iloc[:,:-1]\n",
    "        y_test        = df2_test.iloc[:,-1:]\n",
    "        feature_names = df2_train.columns[:-1]\n",
    "        \n",
    "    decision_tree = DecisionTreeClassifier(criterion = criteria, splitter = split_type, max_depth = max_depth, \n",
    "                                       min_samples_split = min_split , min_samples_leaf = min_leaf)\n",
    "    decision_tree.fit(X_train, y_train)\n",
    "    graph = Source(tree.export_graphviz(decision_tree , out_file=None, feature_names=feature_names,\n",
    "                                        class_names=['0','1'] , filled = True))                  #'decision_tree.dot'\n",
    "    display(SVG(graph.pipe(format='svg')))\n",
    "    \n",
    "    class_names=[0,1]\n",
    "    y_pred_train       = decision_tree.predict(X_train)\n",
    "    y_pred_test        = decision_tree.predict(X_test)                     \n",
    "    cnf_matrix_train   = metrics.confusion_matrix(y_train, y_pred_train)\n",
    "    cnf_matrix_test    = metrics.confusion_matrix(y_test , y_pred_test)\n",
    "    cnf_matrix_train   = cnf_matrix_train/len(X_train)\n",
    "    cnf_matrix_test    = cnf_matrix_test/len(y_test)\n",
    "    \n",
    "    print(\"Confusion Matrix Training set\")\n",
    "    fig, ax = plt.subplots()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    sns.heatmap(pd.DataFrame(cnf_matrix_train), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "    ax.xaxis.set_label_position(\"top\")\n",
    "    plt.tight_layout()\n",
    "    plt.title('Confusion matrix', y=1.1)\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"Confusion Matrix Test set\")\n",
    "    fig, ax = plt.subplots()\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks, class_names)\n",
    "    plt.yticks(tick_marks, class_names)\n",
    "    sns.heatmap(pd.DataFrame(cnf_matrix_test), annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "    ax.xaxis.set_label_position(\"top\")\n",
    "    plt.tight_layout()\n",
    "    plt.title('Confusion matrix', y=1.1)\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "    \n",
    "    print(\"=================On test set=================\")\n",
    "    print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred_test))\n",
    "    print(\"Precision:\",metrics.precision_score(y_test, y_pred_test))\n",
    "    print(\"Recall:\",metrics.recall_score(y_test, y_pred_test))\n",
    "    print(\"F1 Score:\",metrics.f1_score(y_test, y_pred_test))\n",
    "    \n",
    "    return decision_tree\n",
    "\n",
    "inter=interactive(run_decission_tree, dataset = [1,2], criteria = [\"gini\", \"entropy\"], \n",
    "                  split_type = [\"best\", \"random\"],\n",
    "                  max_depth = [None,1,2,3,4,5,6,7,8,9,10], min_split = (0.01,0.5), min_leaf = (0.01,0.5) )\n",
    "display(inter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
